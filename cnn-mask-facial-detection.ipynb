{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7553 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory(\n",
    "        'best_dataset/',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = test_datagen.flow_from_directory(\n",
    "        'datasets/test',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32, \n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=48, kernel_size=3, activation='relu', input_shape = [64,64,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=48, kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tensorflow.python.keras.layers.core.Dropout at 0x2334c602248>,)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.add(tf.keras.layers.Flatten())\n",
    "tf.keras.layers.Dropout(0.7),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 256 neurons \n",
    "cnn.add(tf.keras.layers.Dense(units=50, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 neuron for final results\n",
    "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer= 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  3/237 [..............................] - ETA: 24s - loss: 0.7080 - accuracy: 0.5104"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\dev\\notebooks\\mask-facial-detection\\venv\\lib\\site-packages\\PIL\\Image.py:952: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237/237 [==============================] - 25s 103ms/step - loss: 0.4428 - accuracy: 0.7754 - val_loss: 0.4580 - val_accuracy: 0.8500\n",
      "Epoch 2/20\n",
      "237/237 [==============================] - 24s 103ms/step - loss: 0.2869 - accuracy: 0.8850 - val_loss: 0.3954 - val_accuracy: 0.8500\n",
      "Epoch 3/20\n",
      "237/237 [==============================] - 24s 102ms/step - loss: 0.2301 - accuracy: 0.9101 - val_loss: 0.3878 - val_accuracy: 0.8600\n",
      "Epoch 4/20\n",
      "237/237 [==============================] - 26s 109ms/step - loss: 0.1993 - accuracy: 0.9206 - val_loss: 0.2977 - val_accuracy: 0.8900\n",
      "Epoch 5/20\n",
      "237/237 [==============================] - 24s 101ms/step - loss: 0.1780 - accuracy: 0.9245 - val_loss: 0.2227 - val_accuracy: 0.9300\n",
      "Epoch 6/20\n",
      "237/237 [==============================] - 24s 102ms/step - loss: 0.1555 - accuracy: 0.9411 - val_loss: 0.1970 - val_accuracy: 0.9400\n",
      "Epoch 7/20\n",
      "237/237 [==============================] - 24s 101ms/step - loss: 0.1349 - accuracy: 0.9476 - val_loss: 0.2890 - val_accuracy: 0.8700\n",
      "Epoch 8/20\n",
      "237/237 [==============================] - 24s 101ms/step - loss: 0.1315 - accuracy: 0.9495 - val_loss: 0.1263 - val_accuracy: 0.9600\n",
      "Epoch 9/20\n",
      "237/237 [==============================] - 24s 101ms/step - loss: 0.1095 - accuracy: 0.9574 - val_loss: 0.1458 - val_accuracy: 0.9400\n",
      "Epoch 10/20\n",
      "237/237 [==============================] - 25s 105ms/step - loss: 0.1000 - accuracy: 0.9611 - val_loss: 0.1184 - val_accuracy: 0.9600\n",
      "Epoch 11/20\n",
      "237/237 [==============================] - 25s 105ms/step - loss: 0.0858 - accuracy: 0.9700 - val_loss: 0.1796 - val_accuracy: 0.9400\n",
      "Epoch 12/20\n",
      "237/237 [==============================] - 25s 105ms/step - loss: 0.0922 - accuracy: 0.9675 - val_loss: 0.1593 - val_accuracy: 0.9400\n",
      "Epoch 13/20\n",
      "237/237 [==============================] - 25s 105ms/step - loss: 0.0729 - accuracy: 0.9756 - val_loss: 0.1448 - val_accuracy: 0.9500\n",
      "Epoch 14/20\n",
      "237/237 [==============================] - 25s 105ms/step - loss: 0.0741 - accuracy: 0.9727 - val_loss: 0.0826 - val_accuracy: 0.9600\n",
      "Epoch 15/20\n",
      "237/237 [==============================] - 25s 105ms/step - loss: 0.0591 - accuracy: 0.9768 - val_loss: 0.1147 - val_accuracy: 0.9500\n",
      "Epoch 16/20\n",
      "237/237 [==============================] - 24s 101ms/step - loss: 0.0590 - accuracy: 0.9788 - val_loss: 0.0741 - val_accuracy: 0.9700\n",
      "Epoch 17/20\n",
      "237/237 [==============================] - 24s 101ms/step - loss: 0.0605 - accuracy: 0.9745 - val_loss: 0.1012 - val_accuracy: 0.9700\n",
      "Epoch 18/20\n",
      "237/237 [==============================] - 24s 101ms/step - loss: 0.0487 - accuracy: 0.9825 - val_loss: 0.1757 - val_accuracy: 0.9200\n",
      "Epoch 19/20\n",
      "237/237 [==============================] - 24s 102ms/step - loss: 0.0652 - accuracy: 0.9772 - val_loss: 0.2167 - val_accuracy: 0.8900\n",
      "Epoch 20/20\n",
      "237/237 [==============================] - 25s 105ms/step - loss: 0.0513 - accuracy: 0.9815 - val_loss: 0.1300 - val_accuracy: 0.9500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2334c537608>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(x = training_set, validation_data = test_set, epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('datasets/Validation/Non Mask/real_00022.jpg' , target_size=(100,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 992 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = test_datagen.flow_from_directory(\n",
    "        'new_dataset\\Face Mask Dataset\\Test',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 1s 35ms/step - loss: 0.3442 - accuracy: 0.9385\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3442428708076477, 0.9385080933570862]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.evaluate(test_set, batch_size=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = int(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = f\"./img_classifier/{ts}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./img_classifier/1609189008/assets\n"
     ]
    }
   ],
   "source": [
    "cnn.save(filepath=file_path, save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'WithMask': 0, 'WithoutMask': 1}\n"
     ]
    }
   ],
   "source": [
    "print(test_set.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
